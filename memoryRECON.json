{
  "project_scope": {
    "name": "Reconciliation Engine (PoC)",
    "classification": "mission_critical_banking_system_poc_non_prod",
    "criticality_level": "tier_1_poc",
    "primary_constraint": "30_minute_sla",
    "volume_constraint": "10000_transactions",
    "processing_model": "eod_batch_one_shot",
    "architecture_principle": "sun_do_more_with_less",
    "poc_showcase_requirement": "demonstrate_prod_skills_in_non_prod_env",
    "junior_engineer_feasibility": "high_automation_clear_design_manageable_learning_curve_efficient_delivery",
    "quant_message_format": "udp_packet_like_self_contained_kafka_transport"
  },
  "architectural_contracts": {
    "core_contract_id": "RECONCILIATION-ENGINE-CORE-V1.0-20250704-OMNI",
    "architecture_type": "microservices",
    "transport_backbone": "Apache Kafka",
    "semantic_principles": {
      "microservice_decomposition": "independently_deployable_units",
      "qa_test_harness_inclusion": "mandatory_for_poc_showcase"
    },
    "mandated_libraries_overview": [
      "central_common_libraries (shared DTOs, validation, config, security, fault-tolerance, error-handling, logging/monitoring)"
    ]
  },
  "microservice_topology_overview": {
    "data_flow_topology": "naas -> orchestrator -> matcher -> [reporter|escalator|monitor]",
    "services": {
      "naas": {
        "semantic_role": "sla_entry_point_etl_normalization",
        "finalization_status": "FINALIZED_FOR_POC",
        "sla_slice": "2min",
        "input": "eod_file_delivery_via_webhook",
        "output": "kafka_unified_dtos_input_topic",
        "concurrency": "8",
        "tps": "500"
      },
      "orchestrator": {
        "semantic_role": "central_coordinating_intelligence",
        "finalization_status": "FINALIZED_FOR_POC",
        "sla_slice": "5min",
        "input": "kafka_unified_dtos_input_topic",
        "output": "kafka_matching_input_topic",
        "core_function": "husband_wife_quant_co_location (hash_based_transaction_groups_on_transactionId)"
      },
      "matcher": {
        "service_id": "MATCHING-ENGINE-V1.0-GMNDS-20250704",
        "scope": "PoC",
        "cir": 98,
        "adi": 100,
        "overall_project_sla": {
          "duration_minutes": 30,
          "volume_combined_quants": 1000000,
          "nature": "EOD_one_shot_batch_job",
          "start_point": "NaaS_Ingestion_Point"
        },
        "maas_internal_sla_time_budget_minutes": 10,
        "guiding_principle": "sun_do_more_with_less",
        "organizational_context": {
          "project_structure": "Multi_module_Maven",
          "poc_strategy": "CQ_Gemini_2_5_Pro_core_functionality_permissible_workarounds_actual_concurrency_parallelization_demonstrated",
          "poc_data_volume_quants": 10000
        },
        "sub_components": {
          "kafka_consumer_buffer": {
            "role": "Immediate entry point for Quants into Maas. Temporary in-memory holding area.",
            "input_source_kafka_topic": "Matching_Input_Topic",
            "message_type": "Prepared batches of Quants (Unified DTOs). Each batch is a collection of transaction groups (e.g., {H1, W1}, {H2, W2}), where each group contains all Quants for a single, unique transaction identifier, co-located by the Orchestrator.",
            "upstream_producer": "Reconciliation Batch Orchestrator (3. MATCHING INTERFACE)",
            "consumption_model": "Multiple Kafka consumer group instances (concurrent workers) for high-throughput consumption",
            "kafka_consumer_configuration": {
              "max_poll_records": 2000,
              "fetch_min_bytes_mb": 1,
              "fetch_max_wait_ms": 250,
              "enable_auto_commit": false,
              "isolation_level": "read_committed"
            },
            "number_of_consumer_instances": 8,
            "internal_buffer_capacity_quants": 50000,
            "overflow_behavior": "Apply internal backpressure to Kafka consumer (blocking polls) combined with explicit error logging if buffer persistently full for >10 seconds",
            "processing_semantics": "At-least-once (default Kafka consumer)"
          },
          "matching_engine_core_cme": {
            "role": "Central processing unit within Maas, performing multi-stage matching. Single logical component, internally partitioned by concurrent workers.",
            "input": "Pre-grouped transaction sets (e.g., {H1, W1}) from Maas's Kafka Consumer Buffer",
            "internal_parallelization": {
              "cme_worker_pool_size_threads": 32,
              "concurrency_framework": "Utilize central fault-tolerance library for managing worker pools",
              "work_distribution_to_workers": "Utilize a single shared ConcurrentLinkedQueue for worker consumption, fed by the Kafka Consumer Buffer"
            },
            "waterfall_matching_algorithm": "Each CME worker processes a single transaction group through sequential steps. No internal hops between these stages per worker.",
            "stages": {
              "exact_match_module_soulmate": {
                "logic": "Compares Quants (Husband and Wife within the transaction group) on explicitly defined exact match keys",
                "exact_match_keys": [
                  {
                    "field": "transactionId",
                    "case_sensitive": true
                  },
                  {
                    "field": "amount",
                    "tolerance": 0
                  },
                  {
                    "field": "currency",
                    "case_sensitive": true
                  }
                ],
                "uses_internal_lookups": true,
                "exit_condition": "If exact match found, processing for this transaction group ends, outputting Matched Quant."
              },
              "fuzzy_match_module": {
                "execution_condition": "Executed ONLY if 1:1 Exact Match Fails.",
                "algorithm": "Levenshtein Distance is the base algorithm for string comparisons",
                "optimization_for_scale": "Implement pre-filtering of candidates using n-gram indexing before applying Levenshtein Distance",
                "configurable_tolerance": [
                  {
                    "field": "description",
                    "algorithm": "Levenshtein_distance",
                    "value": 2,
                    "operator": "<="
                  },
                  {
                    "field": "amount",
                    "algorithm": "amount_variance",
                    "value": 0.05,
                    "unit": "USD",
                    "operator": "<="
                  },
                  {
                    "field": "amount",
                    "algorithm": "percentage_variance",
                    "value": 0.01,
                    "unit": "percent",
                    "operator": "<="
                  }
                ],
                "uses_internal_lookups": true,
                "exit_condition": "If fuzzy match found, processing for this transaction group ends, outputting Fuzzy Matched Quant."
              },
              "unmatched_exception_router_module": {
                "execution_condition": "Executed ONLY if both Exact and Fuzzy Match Fail.",
                "logic": "Tags Quants as 'Unreconciled & Exceptions' (URE).",
                "reason_codes": [
                  "NO_EXACT_MATCH",
                  "FUZZY_TOLERANCE_EXCEEDED",
                  "TIMING_DIFFERENCE_FLAG",
                  "MALFORMED_DATA",
                  "MISSING_COUNTERPARTY",
                  "RULE_ENGINE_FAILURE"
                ],
                "enrichment": "Adds detailed metadata explaining the failure, referencing relevant fields.",
                "output_to_dispatcher": "Handoff to Output Dispatcher for URE routing."
              }
            },
            "output": "Matched, Fuzzy Matched, or URE Quants (tagged with match type/status, confidence score for fuzzy, and error details) are passed to the Output Dispatcher."
          },
          "matching_rule_management": {
            "role": "Manages, stores, and provides matching rules to CME.",
            "rule_definition_format": "YAML-based Domain-Specific Language (DSL) for matching rules",
            "rule_storage": "Stored in Git repository, pulled at service startup",
            "rule_updates": "Requires service restart for rule updates (accepted for POC). Future consideration: polling from Git every 5 minutes."
          },
          "internal_state_lookups": {
            "role": "Manages in-memory data required for CME (e.g., matching rules, reference data, potential pending Quants).",
            "matching_rule_cache": {
              "purpose": "Store active matching rules for CME to avoid external lookups per transaction.",
              "sizing_mb": 50,
              "population_strategy": "Loaded at startup from Config Server (via common_config_utils).",
              "refresh_invalidation_strategy": "Manual refresh via Actuator endpoint /actuator/refreshRules. Max staleness tolerance: 10 minutes.",
              "redundancy_ha": "Not required for POC (single instance)."
            },
            "reference_data_cache": {
              "purpose": "Store master data or reference tables needed for matching/enrichment (e.g., list of valid merchant IDs, standard account types) in memory.",
              "sizing_mb": 200,
              "population_strategy": "Loaded at startup from internal configuration or a daily batch file.",
              "refresh_invalidation_strategy": "Scheduled refresh every 1 hour. Max staleness tolerance: 1 hour."
            },
            "pending_quants_matching_window_state": {
              "purpose": "No cross-batch/temporal matching state required within Maas; Orchestrator guarantees co-located Quants per transaction ID within a single batch.",
              "storage_technology": "Not applicable",
              "persistence_for_recovery": "Not applicable"
            }
          },
          "reconciliation_metadata_management": {
            "role": "Collects and manages per-batch/job reconciliation metadata and statistics within Maas for subsequent reporting.",
            "internal_buffer_job_meta": {
              "description": "In-memory, non-persistent buffer for collecting batchwise metadata about the recon process.",
              "structure": "ConcurrentHashMap<BatchId, BatchMetadataDTO> for aggregation within a batch.",
              "capacity_retention_last_batches": 100,
              "overflow_behavior": "LRU eviction"
            },
            "recon_meta_dto_schema": "JSON Schema (defined in common_dto library).",
            "data_points_collected": [
              "total Quants consumed",
              "total Quants produced",
              "matchedExactCount",
              "fuzzyMatchedCount",
              "ureCount",
              "processingTimeMs (for CME per batch)",
              "errorCounts (by type)",
              "resourceUtilizationSnapshot (CPU%, Mem% usage of Maas during batch processing)",
              "KafkaProducerMetrics (records_sent, produce_latency for this batch)"
            ],
            "collection_logic": "CME workers will atomically update JOB_META as they process transaction groups within a batch.",
            "publishing_trigger": "After a full Orchestrator-defined batch is completely processed and its Quants are sent to output topics, the aggregated JOB_META for that batch is sent to the Output Dispatcher."
          },
          "output_dispatcher": {
            "role": "Handles routing of processed Quants from CME and JOB_META to respective Kafka topics.",
            "output_buffers_in_memory": {
              "recon_bucket": {
                "purpose": "In-memory buffer for Matched and Fuzzy Matched Quants.",
                "persistence": "NOT persistent.",
                "capacity_quants": 50000,
                "overflow_behavior": "Apply internal backpressure to CME (blocking output)."
              },
              "ure_bucket": {
                "purpose": "In-memory buffer for Unreconciled & Exceptions (URE) Quants.",
                "persistence": "NOT persistent.",
                "capacity_quants": 5000,
                "overflow_behavior": "Apply internal backpressure to CME (blocking output)."
              },
              "job_meta_buffer": {
                "purpose": "In-memory buffer for Recon-meta DTOs (from Recon-meta Management).",
                "persistence": "NOT persistent.",
                "capacity_batch_metadata_dtos": 100,
                "overflow_behavior": "Oldest entries overwritten (LRU)."
              }
            },
            "kafka_producers_internal": {
              "matching_output_producer": {
                "topic": "Matching_Output_Topic",
                "source_buffer": "RECON BUCKET",
                "producer_configuration": "acks=all, retries=5, batch.size=16384 bytes, linger.ms=100ms. Utilize central fault-tolerance library for adaptive pacing."
              },
              "escalation_output_producer": {
                "topic": "Escalation_Topic",
                "source_buffer": "URE BUCKET",
                "producer_configuration": "acks=all, retries=5, batch.size=16384 bytes, linger.ms=100ms. Adaptive pacing highly recommended."
              },
              "recon_meta_output_producer": {
                "topic": "Recon_Metadata_Topic",
                "source_buffer": "JOB_META Buffer",
                "producer_configuration": "acks=all, retries=5, batch.size=16384 bytes, linger.ms=100ms. Adaptive pacing recommended."
              }
            },
            "serialization_formats": {
              "matched_quants": "Avro with Schema Registry integration.",
              "ure_quants": "Avro with Schema Registry integration.",
              "recon_meta_dto": "Avro with Schema Registry integration."
            }
          },
          "error_handling_dlq": {
            "role": "Cross-cutting concern ensuring resilience and data integrity within Maas. Captures and isolates Quants failing internal Maas processing.",
            "error_categories": [
              "MATCH_RULE_EXECUTION_FAILURE",
              "INVALID_STATE_FOR_MATCH",
              "UNEXPECTED_DATA_PATTERN",
              "EXTERNAL_LOOKUP_FAILURE_TRANSIENT",
              "EXTERNAL_LOOKUP_FAILURE_PERMANENT",
              "BUFFER_OVERFLOW",
              "KAFKA_PRODUCER_FAILURE",
              "DESERIALIZATION_ERROR"
            ],
            "dlq_strategy": "Dedicated Kafka DLQ topic (Maas_DLQ_Topic) with 7-day retention. Manual re-processing via external tool for failed messages.",
            "error_tagging": "Failed Quants (if routed to DLQ) are enriched with context (error code, message, timestamp, problematic fields, source transaction ID).",
            "logging_strategy": "Detailed error logging via logging-monitoring central library, including original message snippets for debugging."
          },
          "performance_scaling_manager": {
            "role": "Cross-cutting concern ensuring Maas meets its SLA contributions and operates efficiently.",
            "metrics_collection": {
              "description": "Emits detailed metrics to Monitoring as a Service via logging-monitoring central library.",
              "metrics": [
                {
                  "name": "total Quants consumed",
                  "type": "counter"
                },
                {
                  "name": "total Quants produced",
                  "type": "counter"
                },
                {
                  "name": "matchedExactCount",
                  "type": "counter_per_second_per_batch"
                },
                {
                  "name": "fuzzyMatchedCount",
                  "type": "counter_per_second_per_batch"
                },
                {
                  "name": "ureCount",
                  "type": "counter_per_second_per_batch"
                },
                {
                  "name": "average_latency_per_match",
                  "type": "gauge",
                  "unit": "ms"
                },
                {
                  "name": "P99_latency_per_match",
                  "type": "gauge",
                  "unit": "ms"
                },
                {
                  "name": "internal_buffer_depths",
                  "type": "gauge"
                },
                {
                  "name": "CPU_Memory_Network_Disk_IO_utilization",
                  "type": "gauge_aggregated"
                },
                {
                  "name": "Kafka_consumer_lag",
                  "type": "gauge_per_partition",
                  "unit": "seconds"
                },
                {
                  "name": "Kafka_producer_rates",
                  "type": "gauge_per_topic",
                  "unit": "records_per_second"
                },
                {
                  "name": "cache_hit_ratio_lookups",
                  "type": "gauge"
                },
                {
                  "name": "cache_miss_ratio_lookups",
                  "type": "gauge"
                }
              ]
            },
            "alerting": {
              "alert_rules": [
                {
                  "name": "Critical_Kafka_Consumer_Lag",
                  "severity": "CRITICAL",
                  "condition": "Kafka consumer lag > 60 seconds",
                  "notification_channel": "MonaaS, Central_Logging"
                },
                {
                  "name": "Critical_Maas_Latency_Spike",
                  "severity": "CRITICAL",
                  "condition": "P99 Maas latency > 500ms",
                  "notification_channel": "MonaaS, Central_Logging"
                },
                {
                  "name": "Critical_London_Bridge_URE_Count",
                  "severity": "CRITICAL",
                  "condition": "URE count > 100 for a batch",
                  "notification_channel": "MonaaS, Central_Logging"
                },
                {
                  "name": "Warning_Error_Rate_Exceeded",
                  "severity": "WARNING",
                  "condition": "Error rate > 0.1%",
                  "notification_channel": "MonaaS, Central_Logging"
                },
                {
                  "name": "Error_Buffer_Full",
                  "severity": "ERROR",
                  "condition": "Internal buffer is full",
                  "notification_channel": "MonaaS, Central_Logging"
                }
              ]
            },
            "internal_scaling": {
              "description": "Dynamically adjusts CME worker pool size based on internal load (e.g., consumer buffer depth, CPU utilization).",
              "logic_algorithm": "Dynamic adjustment of CME worker pool size (N) based on Kafka consumer buffer depth (if >75% capacity, N++ up to max; if <25% capacity, N-- down to min). Max N = 2x CPU cores, Min N = 4 threads."
            },
            "external_scaling_hpa": {
              "description": "How Maas instances scale horizontally in Kubernetes/cloud environment.",
              "criteria": [
                {
                  "name": "Kafka_consumer_lag",
                  "source": "KEDA",
                  "target_value": 30,
                  "unit": "seconds"
                },
                {
                  "name": "average_CPU_utilization",
                  "value": 60,
                  "unit": "percent"
                }
              ],
              "replicas_min": 2,
              "replicas_max": 8
            },
            "distributed_tracing": "Use of distributed tracing (e.g., OpenTelemetry via security central library) to trace a single transaction's journey through Maas stages."
          },
          "cross_cutting_concerns": {
            "central_library_dependencies": [
              "dto",
              "validation",
              "config",
              "pci",
              "security",
              "resilience",
              "error",
              "monitoring"
            ],
            "fault_tolerance_application": {
              "adaptive_pacing_kafka_producer": "Utilize central fault-tolerance library"
            },
            "testing_strategy": {
              "unit_tests": "High coverage for matching algorithms and rule logic.",
              "integration_tests": "Kafka consumer/producer interactions, rule loading, internal component interactions.",
              "performance_tests": "Simulated transaction matching up to 10,000 Quants/day to validate SLA slice and latency targets.",
              "contract_tests": "Schema compatibility with Matching_Input_Topic and all output topics (Matching_Output_Topic, Escalation_Topic, Recon_Metadata_Topic)."
            }
          }
        }
      },
      "reporter": {
        "service_id": "REPAAS-POC-V1.0-20250704",
        "scope": "PoC",
        "cir": 95,
        "adi": 100,
        "service_identity": {
          "name": "Reporting",
          "aliases": "RepaaS",
          "semantic_role": "analytical_reporting_from_kafka_persistence",
          "classification": "support_service",
          "criticality_level": "tier_2_post_reconciliation"
        },
        "processing_semantic": {
          "reporting_scope_and_granularity": {
            "job_level_reconciliation_summary": {
              "description": "Single report for an entire 30-minute job, printing all batches chronologically within that job.",
              "content_detail": "Batch ID, total input quants, matched count, URE count per batch, arranged chronologically within a job report.",
              "granularity": "Job-level aggregation of batch data"
            },
            "weekly_ure_trend_report": {
              "description": "Counts of UREs by reason code over time.",
              "granularity": "Daily/Weekly Aggregation"
            }
          },
          "data_sources_and_model": {
            "kafka_input_topics": [
              "Recon_Metadata_Topic",
              "Escalation_Topic",
              "Matching_Output_Topic"
            ],
            "persistence_layer": {
              "database_type": "Kafka_Streams_State_Store",
              "role": "Internal, localized, fault-tolerant persistence for read models.",
              "technology": "Apache Kafka Streams (KTable/KStream aggregations)",
              "note": "Strictly no external database connection (e.g., MongoDB)."
            },
            "internal_data_model_conceptual": "Kafka Streams KTables for materialized views of job summaries, batch details, and URE trends."
          },
          "query_patterns_and_performance": {
            "expected_query_patterns": "Querying Kafka Streams local state stores by job ID, date range, URE reason codes.",
            "query_response_times": {
              "job_level_report_generation_p95_seconds": 5,
              "weekly_trend_reports_p95_seconds": 10
            }
          },
          "data_latency_and_freshness": {
            "report_availability_latency_minutes": 15,
            "max_data_staleness_minutes": 15,
            "consistency_model": "Eventual Consistency"
          },
          "user_concurrency_and_report_generation_volume": {
            "concurrent_users_viewing_reports": 5,
            "report_generation_volume": {
              "daily_job_reports_generated": 1,
              "weekly_trend_reports": 5,
              "api_exports_per_day": 10
            },
            "poc_data_volume_quants_max_per_job": 10000
          },
          "report_distribution_and_delivery": {
            "delivery_mechanism": [
              "Web UI Access",
              "Report Export API"
            ],
            "web_ui_endpoint": "/reports",
            "export_api_endpoints": [
              {
                "type": "Job_Report_Export",
                "uri": "/api/reports/job/{jobId}/export",
                "http_method": "GET",
                "export_formats": [
                  "CSV",
                  "JSON"
                ]
              },
              {
                "type": "URE_Trend_Report_Export",
                "uri": "/api/reports/ure/trend/export",
                "http_method": "GET",
                "export_formats": [
                  "CSV",
                  "JSON"
                ]
              }
            ],
            "security_model": "Basic authentication for POC scope (API and UI)."
          },
          "scalability_and_archival": {
            "expected_growth_period_months": 12,
            "projected_growth_target": {
              "data_volume_increase_x": 2,
              "concurrent_users_increase_x": 2,
              "report_generation_increase_x": 2
            },
            "future_solution_recommendation": "Scaling Kafka Streams instances, dedicated reporting microservice cluster, integration with external BI tools/data warehouses (potentially with more robust external persistence).",
            "archival_strategy": "Offload historical Kafka topic data older than 1 year to cold storage (e.g., S3); Kafka Streams state stores would rebuild from compacted topics upon restart/rebalance."
          }
        },
        "resource_constraints_for_poc": {
          "max_ram_mb": 1024,
          "max_cpu_usage_percent_of_single_core": 75
        },
        "sub_components_semantic": {
          "kafka_consumer_group": {
            "order": 1,
            "responsibility": "Parallel consumption of Kafka input topics (Recon_Metadata, Escalation, Matching_Output)"
          },
          "data_buffer": {
            "order": 2,
            "responsibility": "In-memory buffer for incoming Kafka messages before stream processing"
          },
          "report_preparation_arena": {
            "order": 3,
            "responsibility": "Stateful Kafka Streams application for aggregating/materializing data for job-level and trend reports (KTables)"
          },
          "report_generator": {
            "order": 4,
            "responsibility": "Transforms materialized report data from Kafka Streams state stores into final report format (CSV/JSON)"
          },
          "export_rest_api": {
            "order": 5,
            "responsibility": "Exposes HTTP endpoints for report generation requests and downloading generated reports"
          }
        },
        "cross_cutting_concerns": {
          "central_library_dependencies": [
            "dto",
            "config",
            "security",
            "error",
            "monitoring"
          ],
          "fault_tolerance_application": {
            "kafka_streams_resilience": "Leverages Kafka Streams' fault tolerance for state store recovery and processing guarantees."
          },
          "testing_strategy": {
            "unit_tests": "High coverage for Kafka Streams topologies, report generation logic, and API endpoints.",
            "integration_tests": "Kafka Streams application end-to-end with simulated Kafka topics, API endpoint testing.",
            "performance_tests": "Simulated report generation and API export load to validate query response times and resource constraints.",
            "contract_tests": "Schema compatibility with input Kafka topics and output report formats (CSV/JSON)."
          }
        }
      },
      "escalator": {
        "service_id": "ESCAL-SVC-001-PAIRCODE-V1.0-20250705",
        "scope": "PoC",
        "cir": 95,
        "adi": 100,
        "service_identity": {
          "name": "Escalation",
          "aliases": "ExaaS",
          "semantic_role": "human_workflow_ure_resolution",
          "classification": "business_support_service",
          "criticality_level": "tier_2_post_reconciliation"
        },
        "processing_semantic": {
          "objective": {
            "description": "Develop a functional Proof of Concept (POC) for Escalation-as-a-Service (ExaaS).",
            "quantified_goal": "Deliver a working POC of ExaaS within 90 minutes of dedicated pair-coding time.",
            "metrics": [
              "Code Completeness: Core ExaaS components functional.",
              "Functional Flow: Demonstration of URE ingestion, persistence, status update, and API interaction.",
              "Alert Trigger: Ability to demonstrate 'London Bridge' alert on exceeding 100 UREs for a job."
            ]
          },
          "in_scope_functionality": [
            {
              "function": "Consume UREs from Kafka",
              "source": "Escalation_Topic",
              "mechanism": "Kafka Consumer Group (KCG)",
              "constraints": {
                "max_consumption_rate_ures_per_second_peak": 5,
                "max_consumer_lag_tolerance_seconds": 10
              }
            },
            {
              "function": "Manage internal buffers for data flow",
              "mechanism": "java.util.concurrent.LinkedBlockingQueue",
              "detail": "From KCG to MongoDB persistence system.",
              "constraints": {
                "buffer_capacity_ures": 5000,
                "batch_write_size_ures_per_batch": 100,
                "overflow_behavior": "Route to Kafka DLQ topic",
                "dlq_kafka_topic_name": "ure-dlq-topic"
              }
            },
            {
              "function": "Read/write UREs to MongoDB",
              "role": "Source of truth ledger for unmatched/weird items.",
              "constraints": {
                "max_rw_qps_peak": 10,
                "target_persistence_latency_p99_ms": 100
              }
            },
            {
              "function": "Support 'Inspection Arena' concept",
              "detail": "UREs presented for manual inspection by `bankops` (no UI from ExaaS)."
            },
            {
              "function": "Implement 'Status Tracker'",
              "detail": "Observe UREs entering Inspection Arena and update their status in MongoDB Ledger."
            },
            {
              "function": "Implement 'Lean but Powerful Curing Algorithm'",
              "detail": "Human-dependent workflow to try and correct URE issues inside Inspection Arena (not automated curing).",
              "constraints": {
                "workflow_states": [
                  "PENDING_REVIEW",
                  "IN_PROGRESS",
                  "RESOLVED",
                  "REJECTED"
                ]
              }
            },
            {
              "function": "Provide 'Escalation Curing API'",
              "type": "REST API",
              "consumer": "`bankops`",
              "detail": "To interact with UREs in Inspection Area (cure, update status).",
              "constraints": {
                "api_endpoints": [
                  {
                    "uri": "/api/ures/{id}/cure",
                    "method": "POST"
                  },
                  {
                    "uri": "/api/ures/{id}/status",
                    "method": "PUT"
                  }
                ],
                "request_response_schemas": [
                  {
                    "name": "CureRequest",
                    "type": "JSON_SCHEMA_REFERENCE"
                  },
                  {
                    "name": "StatusUpdateRequest",
                    "type": "JSON_SCHEMA_REFERENCE"
                  },
                  {
                    "name": "UreResponse",
                    "type": "JSON_SCHEMA_REFERENCE"
                  }
                ],
                "custom_error_codes": [
                  "URE_NOT_FOUND",
                  "INVALID_STATUS_TRANSITION"
                ],
                "target_api_latency_p99_ms": 200
              }
            },
            {
              "function": "Trigger 'SYSTEM ALERT: Code London Bridge Is Falling Down'",
              "condition": "UREs exceed 100 (1% of 10K total load in a 30min job).",
              "constraints": {
                "alert_mechanism": "Log to system stdout/file, publish to monitoring Kafka topic (if integrated)",
                "alert_notification_channel": "System logs, dedicated monitoring dashboard"
              }
            }
          ],
          "out_of_scope_functionality": [
            "Automated URE curing beyond simple rules or workflow management.",
            "Full historical reporting/auditing within ExaaS beyond the MongoDB ledger's current state (delegated to external systems).",
            "Deployment to Docker/Cloud environments (POC is native Windows only).",
            "High Availability (HA) or automated failover for the single ExaaS instance (POC constraint).",
            "Graphical User Interface (GUI) for Inspection Arena or Curing API (API only)."
          ]
        },
        "technology_alignment": {
          "programming_language": "Java 21",
          "framework": "Spring Boot",
          "build_tool": "Maven",
          "message_broker": "Apache Kafka",
          "stream_processing": "Apache Kafka Streams",
          "persistence": "MongoDB (for URE Ledger)",
          "api_framework": "Spring Web",
          "common_libraries": [
            "common_dto",
            "validation_utils",
            "config_utils",
            "pci_dss",
            "security",
            "fault_tolerance",
            "error_handling",
            "logging_monitoring"
          ]
        },
        "risk_assessment_details": [
          {
            "id": "ESCAL-R-001",
            "type": "Performance/Resource",
            "status": "Mitigated by Design",
            "description": "URE Volume: System design optimized for high volume. POC load is 50K txns total; 'London Bridge' alert covers high URE count (100).",
            "mitigation": "Internal buffers, batch writing, Kafka Consumer Group for parallel consumption, robust MongoDB configuration for scale.",
            "quantified_context": {
              "max_ure_throughput_poc_ures_per_second_peak": 5,
              "cpu_memory_target_peak_load": {
                "max_ram_mb": 512,
                "max_cpu_usage_percent_single_core": 50
              }
            }
          },
          {
            "id": "ESCAL-R-002",
            "type": "SinglePointOfFailure",
            "status": "Accepted for POC",
            "description": "The POC will run as a single instance, making it a SPOF.",
            "mitigation_for_prod": "Implement multi-instance deployment with Kafka Consumer Group for HA and load balancing."
          },
          {
            "id": "ESCAL-R-003",
            "type": "Consistency",
            "status": "Mitigated by Design",
            "description": "Status Consistency: Achieved using `read-your-writes` consistency via MongoDB session transactions or `majority` write concern with `primary` read preference on replica set.",
            "mitigation": "Appropriate MongoDB write/read concerns and transaction implementation."
          },
          {
            "id": "ESCAL-R-004",
            "type": "Audit/Compliance",
            "status": "Mitigated by Design",
            "description": "MongoDB Auditability/Transactions: Achieved using `MongoDB Multi-Document Transactions` for atomicity, ensuring `immutable fields` (`createdAt`, `createdBy`), and capturing `Change Streams` for an external audit log.",
            "mitigation": "Robust schema design, transaction usage, and external audit log integration."
          },
          {
            "id": "ESCAL-R-005",
            "type": "BufferManagement",
            "status": "Mitigated by Design",
            "description": "Buffer Specifics: Managed by `java.util.concurrent.LinkedBlockingQueue` for in-memory, with configured capacity, `batching writes` to MongoDB, and routing overflow to a Kafka `DLQ` topic.",
            "mitigation": "Explicit buffer design and error handling (DLQ)."
          },
          {
            "id": "ESCAL-R-006",
            "type": "ImplementationComplexity",
            "status": "Mitigated by Design",
            "description": "Curing Algorithm Workflow: Defined as a human-dependent workflow with clear steps and an alert threshold, reducing coding ambiguity.",
            "mitigation": "Focus on implementing key workflow states and API interactions; leverage Gemini Pro for rapid code generation for known patterns."
          },
          {
            "id": "ESCAL-R-007",
            "type": "APIContractDefinition",
            "status": "Mitigated by Design",
            "description": "API Contracts: Clear endpoints, request/response schemas (JSON), and explicit error codes (HTTP + custom) for `Escalation Curing API` defined.",
            "mitigation": "Automated code generation for API interfaces based on defined contracts."
          },
          {
            "id": "ESCAL-R-008",
            "type": "EnvironmentSpecific",
            "status": "Mitigated by Override",
            "description": "Windows Native Environment: Potential setup/compatibility issues.",
            "mitigation": "Resolved by `override_cq2025` grant; environment will be prepared/managed to ensure readiness."
          },
          {
            "id": "ESCAL-R-009",
            "type": "DependencyManagement",
            "status": "Mitigated by Override",
            "description": "Common Library Access/Configuration: Potential time loss on dependency issues.",
            "mitigation": "Resolved by `override_cq2025` grant; common libraries will be confirmed/configured."
          }
        ],
        "cross_cutting_concerns": {
          "central_library_dependencies": [
            "common_dto",
            "validation_utils",
            "config_utils",
            "pci_dss",
            "security",
            "fault_tolerance",
            "error_handling",
            "logging_monitoring"
          ],
          "fault_tolerance_application": {
            "retries": "Configured for external calls (e.g., MongoDB, Kafka Producer)",
            "circuit_breakers": "Applied to external dependencies (e.g., MongoDB, Kafka Producer)",
            "timeouts": "Configured for all external I/O operations"
          },
          "testing_strategy": {
            "unit_tests": "High coverage for API logic, MongoDB interactions, and URE status transitions.",
            "integration_tests": "Kafka consumer/producer interactions, MongoDB persistence, API endpoint testing.",
            "performance_tests": "Simulated API calls and URE ingestion load to validate QPS and latency targets.",
            "contract_tests": "Schema compatibility with Kafka input topics and API request/response formats."
          }
        }
      },
      "monitor": {
        "service_id": "MON-SVC-001-FINAL",
        "scope": "PoC",
        "cir": 98,
        "adi": 100,
        "service_identity": {
          "name": "Monitoring",
          "aliases": "MonaaS",
          "semantic_role": "realtime_metrics_aggregation_alerting",
          "classification": "support_service",
          "criticality_level": "tier_2_for_visibility_tier_1_for_reporting_core_sla"
        },
        "processing_semantic": {
          "input_model": {
            "mechanism": "HTTP_Polling",
            "source_microservices": [
              "NaaS",
              "RecBatchOrch",
              "Maas",
              "Reporting",
              "Escalation"
            ],
            "endpoints_polled": [
              {
                "type": "standard_actuator_health",
                "uri": "/actuator/health"
              },
              {
                "type": "custom_actuator_job_status",
                "uri": "/actuator/job-status"
              }
            ]
          },
          "metrics_collected": {
            "standard_actuator_metrics": [
              {
                "name": "jvm.memory.used",
                "tags": "service_name"
              },
              {
                "name": "jvm.memory.max",
                "tags": "service_name"
              },
              {
                "name": "jvm.threads.live",
                "tags": "service_name"
              },
              {
                "name": "system.cpu.usage",
                "tags": "service_name"
              },
              {
                "name": "process.uptime",
                "tags": "service_name"
              },
              {
                "name": "http.server.requests.count",
                "tags": "service_name,uri,method,status"
              },
              {
                "name": "http.server.requests.duration.p95",
                "tags": "service_name,uri,method"
              }
            ],
            "custom_job_specific_metrics": [
              {
                "name": "reconciliation.job.status",
                "tags": "service_name,job_id",
                "type": "Enum(STARTED,IN_PROGRESS,COMPLETED,FAILED)"
              },
              {
                "name": "reconciliation.job.start.time",
                "tags": "service_name,job_id",
                "type": "Timestamp"
              },
              {
                "name": "reconciliation.job.end.time",
                "tags": "service_name,job_id",
                "type": "Timestamp"
              },
              {
                "name": "reconciliation.transactions.processed.total",
                "tags": "service_name,job_id",
                "type": "Counter"
              }
            ],
            "overall_job_metrics_calculated_by_monaas": [
              {
                "name": "overall.reconciliation.job.elapsed.time"
              },
              {
                "name": "overall.reconciliation.job.status"
              }
            ]
          },
          "collection_frequency": {
            "polling_interval_seconds": 10
          },
          "data_retention": {
            "current_state_store": {
              "type": "in_memory",
              "retention_period_unit": "hour",
              "retention_period_value": 1,
              "scope": "latest_granular_per_service"
            },
            "job_run_history_log": {
              "type": "file_log",
              "retention_period_unit": "hours",
              "retention_period_value": 24,
              "scope": "overall_job_summary"
            }
          },
          "alerting_logic": {
            "alert_rules": [
              {
                "name": "Critical_Service_Down",
                "severity": "CRITICAL",
                "condition": "ServiceHealthStatus is DOWN for 2 consecutive polls (20 seconds)",
                "notification_channel": "stdout, monaas-alerts.log"
              },
              {
                "name": "Critical_Job_Failure",
                "severity": "CRITICAL",
                "condition": "overall.reconciliation.job.status is FAILED",
                "notification_channel": "stdout, monaas-alerts.log"
              },
              {
                "name": "Critical_SLA_Breach",
                "severity": "CRITICAL",
                "condition": "overall.reconciliation.job.elapsed.time > 30 minutes at job completion",
                "notification_channel": "stdout, monaas-alerts.log"
              },
              {
                "name": "Warning_High_CPU",
                "severity": "WARNING",
                ""condition": "system.cpu.usage > 85% for 3 consecutive polls (30 seconds)",
                "notification_channel": "stdout, monaas-alerts.log"
              },
              {
                "name": "Warning_High_Error_Rate",
                "severity": "WARNING",
                "condition": "http.server.requests.count (for errors) indicates error rate > 1% of total requests over last 1 minute",
                "notification_channel": "stdout, monaas-alerts.log"
              }
            ]
          },
          "data_volume_projection": {
            "unique_time_series_estimate": 120,
            "data_points_per_second_ingestion": 12,
            "current_state_store_memory_estimate_mb": 50
          },
          "latency_targets": {
            "metric_to_dashboard_display_latency_seconds": 15,
            "alert_condition_to_logged_latency_seconds": 5
          },
          "future_scalability": {
            "current_capacity_microservices": 5,
            "expected_growth_period_months": 12,
            "projected_growth_target": "10_microservices (2x), 2x_metric_volume",
            "future_solution_recommendation": "Dedicated Prometheus/Grafana stack with persistent time-series storage"
          }
        },
        "sub_components_semantic": {
          "service_polling_agent": {
            "responsibility": "Initiates_HTTP_polling_requests"
          },
          "raw_status_ingester": {
            "responsibility": "Parses_and_validates_raw_HTTP_responses"
          },
          "overall_job_state_processor": {
            "responsibility": "Aggregates_and_calculates_overall_job_status"
          },
          "current_state_store": {
            "responsibility": "In_memory_cache_for_latest_statuses"
          },
          "dashboard_renderer": {
            "responsibility": "Generates_simple_web_UI"
          },
          "sla_health_alerting": {
            "responsibility": "Monitors_state_triggers_log_alerts"
          }
        },
        "cross_cutting_concerns": {
          "central_library_dependencies": [
            "logging_monitoring",
            "error_handling"
          ],
          "testing_strategy": {
            "unit_tests": "High coverage for polling logic, metric aggregation, and alert condition evaluation.",
            "integration_tests": "Simulated HTTP polling against mock service endpoints, alert logging verification.",
            "performance_tests": "Simulated metric ingestion volume to validate latency targets and resource utilization.",
            "contract_tests": "Verification of expected metric formats from polled endpoints."
          }
        }
      }
    }
  }
}
    }
  },
  "microservice_level_memory": {
    "common": {
      "library_id": "CENTRAL-LIB-UNIFIED-V1.0-20250706-POC",
      "scope": "PoC",
      "cir": 98,
      "adi": 100,
      "purpose": "Unified central utility library for reconciliation microservices",
      "deployment_type": "Shaded JAR",
      "internal_packages": {
        "dto": {
          "purpose": "Unified DTO schema, Avro encoding, error enums",
          "behavior": "Defines and version-controls immutable Avro DTOs shared across microservices",
          "construction_pattern": "Builder pattern, standard error enums"
        },
        "validation": {
          "purpose": "Custom validators, YAML rule engine",
          "behavior": "Executes YAML-driven rule evaluations with layered exception hierarchy",
          "performance_p99_latency_us": 100
        },
        "config": {
          "purpose": "Dynamic config loaders, feature flags, secrets",
          "behavior": "Loads config from env, system props, and YAML; supports hot reload",
          "secret_management": "Fetches and rotates secrets via Vault/AWS Secrets Manager"
        },
        "pci": {
          "purpose": "PAN masking, PCI audit hooks",
          "behavior": "Masks PANs and generates PCI audit events; Luhn and expiry validation included",
          "security_constraint": "No in-memory retention of sensitive cardholder data"
        },
        "security": {
          "purpose": "TLS setup, JWT parsing, sanitization",
          "behavior": "Handles TLS, JWT, OAuth2 token parsing, and input sanitization",
          "encryption_helpers": "AES-GCM encryption"
        },
        "resilience": {
          "purpose": "Circuit breakers, retries, timeouts",
          "behavior": "Applies retries, circuit breakers, timeouts, and fallback patterns",
          "integration": "Spring annotations + internal registries"
        },
        "error": {
          "purpose": "Custom exceptions, DLQ routing, trace injection",
          "behavior": "Propagates typed exceptions and maps to HTTP status codes",
          "trace_id_injection": "MDC + DLQ routing logic"
        },
        "monitoring": {
          "purpose": "Structured logs, metrics, audit spans",
          "behavior": "Emits structured logs, custom metrics, and OpenTelemetry traces",
          "audit_logging": "PCI events routed to audit logger stream"
        }
      },
      "overall_performance": {
        "p99_call_latency_ms": 1,
        "code_coverage_percent": 90
      },
      "external_dependencies": [
          "SLF4J",
          "Micrometer",
          "OpenTelemetry",
          "Resilience4j"
        ]
    },
    "naas": {
      "service_id": "NAAS-POC-V1.0-20250706",
      "scope": "PoC",
      "cir": 98,
      "adi": 100,
      "stages": {
        "file_ingestion": {
          "sources": [
            "Switch SQL Dumps",
            "VISA CSV Files"
          ],
          "mechanism": "SFTP/FTPS with SHA256 checksum validation",
          "volume_max_tx_combined_per_day": 10000,
          "trigger": "Webhook API (OAuth2, idempotent)",
          "arrival_window": "23:00â€“23:15 IST"
        },
        "etl": {
          "parsing_mechanism": "Stream-based: Apache CSV, custom SQL parser",
          "concurrency_thread_pool_size": 8,
          "output_format": "Source-specific JSON DTOs",
          "error_handling_dlq": "naas-etl-dlq"
        },
        "validation": {
          "rules_configuration": "YAML-configured via common_config_utils",
          "concurrency_thread_pool_size": 8,
          "rule_sets": [
            "Switch domain-specific",
            "VISA domain-specific"
          ],
          "dlq": "naas-validation-dlq"
        },
        "queueing": {
          "mechanism": "In-memory ConcurrentLinkedQueue",
          "capacity_dtos": 5000,
          "behavior": "Backpressure on overflow"
        },
        "normalization": {
          "mapping_mechanism": "YAML-based, in-memory lookup",
          "concurrency_thread_pool_size": 8,
          "output_format": "UnifiedDTO (Quants)",
          "dlq": "naas-normalization-dlq"
        },
        "kafka_publishing": {
          "topic": "UnifiedDTOs_Input",
          "format": "Avro, Schema Registry",
          "partition_key": "transactionId",
          "adaptive_pacing": "Yes, based on lag",
          "dlq_behavior": "Sends raw objects to DLQ"
        },
        "monitoring_observability": {
          "metrics": [
            "ETL throughput",
            "Validation throughput",
            "Queue depth",
            "DLQ count"
          ],
          "alerts": "Failure rates > thresholds trigger MonaaS",
          "tracing": "OpenTelemetry from Ingestion to Kafka"
        }
      },
      "cross_cutting_concerns": {
        "central_library_dependencies": [
          "dto",
          "validation",
          "config",
          "pci",
          "security",
          "resilience",
          "error",
          "monitoring"
        ],
        "fault_tolerance_application": {
          "retries": "Configured for external calls (e.g., SFTP, Webhook)",
          "circuit_breakers": "Applied to external dependencies (e.g., Webhook, Kafka Producer)",
          "timeouts": "Configured for all external I/O operations"
        },
        "testing_strategy": {
          "unit_tests": "High coverage for business logic (ETL, Validation, Normalization)",
          "integration_tests": "Kafka producer/consumer interactions, file ingestion",
          "performance_tests": "Simulated file ingestion up to 10,000 tx/day to validate SLA slice",
          "contract_tests": "Schema compatibility with UnifiedDTOs_Input topic"
        }
      }
    },
    "orchestrator": {
      "service_id": "RECONCILIATION-BATCH-ORCHESTRATOR-V1.0-20250705",
      "scope": "PoC",
      "cir": 98,
      "adi": 100,
      "overall_project_sla": {
        "duration_minutes": 30,
        "volume_combined_quants": 1000000,
        "nature": "EOD_one_shot_batch_job",
        "start_point": "NaaS_Ingestion_Point"
      },
      "orchestrator_internal_sla_time_budget_minutes": 5,
      "guiding_principle": "sun_do_more_with_less",
      "organizational_context": {
        "project_structure": "Multi_module_Maven",
        "poc_strategy": "CQ_Gemini_2_5_Pro_core_functionality_permissible_workarounds_actual_concurrency_parallelization_demonstrated",
        "poc_data_volume_quants": 10000
      },
      "sub_components": {
        "kafka_consumer_buffer": {
          "role": "Immediate entry point for Quants into Orchestrator. Temporary in-memory holding area.",
          "input_source_kafka_topic": "UnifiedDTOs_Input",
          "message_type": "Prepared batches of Quants (Unified DTOs). Each batch is a collection of transaction groups (e.g., {H1, W1}, {H2, W2}), where each group contains all Quants for a single, unique transaction identifier, co-located by the Orchestrator.",
          "upstream_producer": "NaaS",
          "consumption_model": "Multiple Kafka Consumer Group instances run concurrently to pull DTOs from partitions",
          "kafka_consumer_configuration": {
            "max_poll_records": 500,
            "fetch_min_bytes_kb": 512,
            "fetch_max_wait_ms": 100,
            "enable_auto_commit": false,
            "isolation_level": "read_committed"
          },
          "number_of_consumer_instances": 2,
          "internal_buffer_capacity_quants": 1000,
          "overflow_behavior": "Apply internal backpressure to Kafka consumer (blocking polls) combined with explicit error logging if buffer persistently full for >5 seconds",
          "processing_semantics": "At-least-once (default Kafka consumer)"
        },
        "batch_preparation_arena": {
          "component": "Reconciliation Engine - Batch Preparation Arena",
          "contract_id": "RECON-BATCH-LOGIC-V1.0-FINALIZED",
          "status": "FINALIZED",
          "finalized_date": "2025-07-10T21:00:00+05:30",
          "description": "This component is responsible for deterministic pairing and batching of unified financial Quants before forwarding them to the Matcher service.",
          "design_objective": "To guarantee that both sides of a financial transaction (i.e., the 'Husband-Wife' pair â€” one from VISA, one from Switch) are deterministically grouped together in the same batch sent to the Matcher, thereby preventing hallucinations, UREs, and partial evaluations downstream.",
          "quant_input": {
            "format": "Unified Quant DTO (POJO)",
            "fields": [
              "transactionId",
              "amount",
              "currency",
              "transactionDate",
              "sourceSystem"
            ],
            "origin": ["Switch", "VISA"],
            "ingestion_topic": "UnifiedDTOs_Input"
          },
          "pairing_mechanism": {
            "routing_strategy": "Deterministic Hashing",
            "hashing_algorithm": "bucketId = abs(hash(transactionId)) % 16",
            "buckets": 16,
            "per_bucket_state": {
              "pair_buffer_map": "Map<String, List<Quant>>",
              "entry_condition": "Each incoming Quant is routed into its hash-determined bucket",
              "pairing_condition": "Emit pair only when List<Quant> for transactionId reaches size 2",
              "incomplete_pair_timeout_ms": 30000,
              "incomplete_pair_behavior": "After 30s, emit incomplete Quant with 'incompletePair=true' flag in metadata"
            }
          },
          "batching_mechanism": {
            "per_worker_batch_buffer": "List<List<Quant>>",
            "flush_triggers": {
              "max_quants_per_batch": 100,
              "max_wait_time_ms": 5000
            },
            "flush_policy": "Flush to matcher when either 100 Quants are collected OR 5 seconds have elapsed since last flush",
            "flush_destination": "Kafka topic: Matching_Input_Topic",
            "kafka_keying": "transactionId used as message key to preserve partition affinity"
          },
          "system_guarantees": {
            "guaranteed_pair_co_location": true,
            "no_partial_pairs_in_matcher": true,
            "deterministic_bucket_assignment": true,
            "bounded_memory": true,
            "flush_compliance_with_sla": true
          },
          "notes": [
            "This architecture ensures full alignment between orchestrator logic and matcher requirements.",
            "All batch flushing is driven by both content size and temporal threshold.",
            "The use of deterministic routing prevents edge-case mismatches, even under load skew or arrival jitter.",
            "This memory is now the canonical source of truth for batch formation and emission in the PoC scope."
          ]
        },
        "matching_interface": {
          "role": "Handoff to External Matching as a Service.",
          "input_source": "Batch Preparation Arena",
          "parallelization_threads": 4,
          "mechanism": "Kafka Producer API to a high-throughput, asynchronous Kafka topic",
          "kafka_producer_configuration": {
            "acks": "all",
            "retries": 5,
            "batch_size_bytes": 16384,
            "linger_ms": 50,
            "delivery_timeout_ms": 60000
          },
          "output_topic_kafka": "Matching_Input_Topic"
        },
        "results_ingestion_buffer": {
          "role": "Temporary holding area for results returning from Matching as a Service.",
          "input_source_kafka_topic": "Matching_Output_Topic",
          "parallelization_consumers": 4,
          "capacity_quants": 1000,
          "overflow_behavior": "Apply internal backpressure to Kafka consumer (blocking polls)"
        },
        "escalation_flow_buffer": {
          "role": "Channels unmatched, anomalous, or problematic transactions for dedicated review and resolution via the Escalation flow.",
          "input_source": "Results Ingestion Buffer",
          "capacity_quants": 100,
          "overflow_behavior": "Apply internal backpressure to Results Ingestion Buffer",
          "output_topic_kafka": "Escalation_Topic"
        }
      },
      "performance_and_resource_constraints": {
        "poc_throughput_target_quants_per_second": 5.5,
        "poc_throughput_average_over": "1_minute",
        "latency_targets": [
          {
            "description": "Kafka Ingestion to Matching_Input_Topic",
            "value_seconds": 1,
            "percentile": "P99",
            "operator": "<"
          },
          {
            "description": "Matching_Output_Topic to Reporting_Input_Topic/Escalation_Topic",
            "value_seconds": 1,
            "percentile": "P99",
            "operator": "<"
          }
        ],
        "resource_limits": {
          "max_ram_mb": 512,
          "max_cpu_usage_percent_of_single_core": 50
        }
      },
      "cross_cutting_concerns": {
        "central_library_dependencies": [
          "dto",
          "validation",
          "config",
          "security",
          "resilience",
          "error",
          "monitoring"
        ],
        "fault_tolerance_application": {
          "adaptive_pacing_kafka_producer": "Utilize central fault-tolerance library"
        }
      }
    },
    "matcher": {
      "service_id": "MATCHING-ENGINE-V1.0-GMNDS-20250704",
      "scope": "PoC",
      "cir": 98,
      "adi": 100,
      "overall_project_sla": {
        "duration_minutes": 30,
        "volume_combined_quants": 1000000,
        "nature": "EOD_one_shot_batch_job",
        "start_point": "NaaS_Ingestion_Point"
      },
      "maas_internal_sla_time_budget_minutes": 10,
      "guiding_principle": "sun_do_more_with_less",
      "organizational_context": {
        "project_structure": "Multi_module_Maven",
        "poc_strategy": "CQ_Gemini_2_5_Pro_core_functionality_permissible_workarounds_actual_concurrency_parallelization_demonstrated",
        "poc_data_volume_quants": 10000
      },
      "sub_components": {
        "kafka_consumer_buffer": {
          "role": "Immediate entry point for Quants into Maas. Temporary in-memory holding area.",
          "input_source_kafka_topic": "Matching_Input_Topic",
          "message_type": "Prepared batches of Quants (Unified DTOs). Each batch is a collection of transaction groups (e.g., {H1, W1}, {H2, W2}), where each group contains all Quants for a single, unique transaction identifier, co-located by the Orchestrator.",
          "upstream_producer": "Reconciliation Batch Orchestrator (3. MATCHING INTERFACE)",
          "consumption_model": "Multiple Kafka consumer group instances (concurrent workers) for high-throughput consumption",
          "kafka_consumer_configuration": {
            "max_poll_records": 2000,
            "fetch_min_bytes_mb": 1,
            "fetch_max_wait_ms": 250,
            "enable_auto_commit": false,
            "isolation_level": "read_committed"
          },
          "number_of_consumer_instances": 8,
          "internal_buffer_capacity_quants": 50000,
          "overflow_behavior": "Apply internal backpressure to Kafka consumer (blocking polls) combined with explicit error logging if buffer persistently full for >10 seconds",
          "processing_semantics": "At-least-once (default Kafka consumer)"
        },
        "matching_engine_core_cme": {
          "role": "Central processing unit within Maas, performing multi-stage matching. Single logical component, internally partitioned by concurrent workers.",
          "input": "Pre-grouped transaction sets (e.g., {H1, W1}) from Maas's Kafka Consumer Buffer",
          "internal_parallelization": {
            "cme_worker_pool_size_threads": 32,
            "concurrency_framework": "Utilize central fault-tolerance library for managing worker pools",
            "work_distribution_to_workers": "Utilize a single shared ConcurrentLinkedQueue for worker consumption, fed by the Kafka Consumer Buffer"
          },
          "waterfall_matching_algorithm": "Each CME worker processes a single transaction group through sequential steps. No internal hops between these stages per worker.",
          "stages": {
            "exact_match_module_soulmate": {
              "logic": "Compares Quants (Husband and Wife within the transaction group) on explicitly defined exact match keys",
              "exact_match_keys": [
                {
                  "field": "transactionId",
                  "case_sensitive": true
                },
                {
                  "field": "amount",
                  "tolerance": 0
                },
                {
                  "field": "currency",
                  "case_sensitive": true
                }
              ],
              "uses_internal_lookups": true,
              "exit_condition": "If exact match found, processing for this transaction group ends, outputting Matched Quant."
            },
            "fuzzy_match_module": {
              "execution_condition": "Executed ONLY if 1:1 Exact Match Fails.",
              "algorithm": "Levenshtein Distance is the base algorithm for string comparisons",
              "optimization_for_scale": "Implement pre-filtering of candidates using n-gram indexing before applying Levenshtein Distance",
              "configurable_tolerance": [
                {
                  "field": "description",
                  "algorithm": "Levenshtein_distance",
                  "value": 2,
                  "operator": "<="
                },
                {
                  "field": "amount",
                  "algorithm": "amount_variance",
                  "value": 0.05,
                  "unit": "USD",
                  "operator": "<="
                },
                {
                  "field": "amount",
                  "algorithm": "percentage_variance",
                  "value": 0.01,
                  "unit": "percent",
                  "operator": "<="
                }
              ],
              "uses_internal_lookups": true,
              "exit_condition": "If fuzzy match found, processing for this transaction group ends, outputting Fuzzy Matched Quant."
            },
            "unmatched_exception_router_module": {
              "execution_condition": "Executed ONLY if both Exact and Fuzzy Match Fail.",
              "logic": "Tags Quants as 'Unreconciled & Exceptions' (URE).",
              "reason_codes": [
                "NO_EXACT_MATCH",
                "FUZZY_TOLERANCE_EXCEEDED",
                "TIMING_DIFFERENCE_FLAG",
                "MALFORMED_DATA",
                "MISSING_COUNTERPARTY",
                "RULE_ENGINE_FAILURE"
              ],
              "enrichment": "Adds detailed metadata explaining the failure, referencing relevant fields.",
              "output_to_dispatcher": "Handoff to Output Dispatcher for URE routing."
            }
          },
          "output": "Matched, Fuzzy Matched, or URE Quants (tagged with match type/status, confidence score for fuzzy, and error details) are passed to the Output Dispatcher."
        },
        "matching_rule_management": {
          "role": "Manages, stores, and provides matching rules to CME.",
          "rule_definition_format": "YAML-based Domain-Specific Language (DSL) for matching rules",
          "rule_storage": "Stored in Git repository, pulled at service startup",
          "rule_updates": "Requires service restart for rule updates (accepted for POC). Future consideration: polling from Git every 5 minutes."
        },
        "internal_state_lookups": {
          "role": "Manages in-memory data required for CME (e.g., matching rules, reference data, potential pending Quants).",
          "matching_rule_cache": {
            "purpose": "Store active matching rules for CME to avoid external lookups per transaction.",
            "sizing_mb": 50,
            "population_strategy": "Loaded at startup from Config Server (via common_config_utils).",
            "refresh_invalidation_strategy": "Manual refresh via Actuator endpoint /actuator/refreshRules. Max staleness tolerance: 10 minutes.",
            "redundancy_ha": "Not required for POC (single instance)."
          },
          "reference_data_cache": {
            "purpose": "Store master data or reference tables needed for matching/enrichment (e.g., list of valid merchant IDs, standard account types) in memory.",
            "sizing_mb": 200,
            "population_strategy": "Loaded at startup from internal configuration or a daily batch file.",
            "refresh_invalidation_strategy": "Scheduled refresh every 1 hour. Max staleness tolerance: 1 hour."
          },
          "pending_quants_matching_window_state": {
            "purpose": "No cross-batch/temporal matching state required within Maas; Orchestrator guarantees co-located Quants per transaction ID within a single batch.",
            "storage_technology": "Not applicable",
            "persistence_for_recovery": "Not applicable"
          }
        },
        "reconciliation_metadata_management": {
          "role": "Collects and manages per-batch/job reconciliation metadata and statistics within Maas for subsequent reporting.",
          "internal_buffer_job_meta": {
            "description": "In-memory, non-persistent buffer for collecting batchwise metadata about the recon process.",
            "structure": "ConcurrentHashMap<BatchId, BatchMetadataDTO> for aggregation within a batch.",
            "capacity_retention_last_batches": 100,
            "overflow_behavior": "LRU eviction"
          },
          "recon_meta_dto_schema": "JSON Schema (defined in common_dto library).",
          "data_points_collected": [
            "total Quants consumed",
            "total Quants produced",
            "matchedExactCount",
            "fuzzyMatchedCount",
            "ureCount",
            "processingTimeMs (for CME per batch)",
            "errorCounts (by type)",
            "resourceUtilizationSnapshot (CPU%, Mem% usage of Maas during batch processing)",
            "KafkaProducerMetrics (records_sent, produce_latency for this batch)"
          ],
          "collection_logic": "CME workers will atomically update JOB_META as they process transaction groups within a batch.",
          "publishing_trigger": "After a full Orchestrator-defined batch is completely processed and its Quants are sent to output topics, the aggregated JOB_META for that batch is sent to the Output Dispatcher."
        },
        "output_dispatcher": {
          "role": "Handles routing of processed Quants from CME and JOB_META to respective Kafka topics.",
          "output_buffers_in_memory": {
            "recon_bucket": {
              "purpose": "In-memory buffer for Matched and Fuzzy Matched Quants.",
              "persistence": "NOT persistent.",
              "capacity_quants": 50000,
              "overflow_behavior": "Apply internal backpressure to CME (blocking output)."
            },
            "ure_bucket": {
              "purpose": "In-memory buffer for Unreconciled & Exceptions (URE) Quants.",
              "persistence": "NOT persistent.",
              "capacity_quants": 5000,
              "overflow_behavior": "Apply internal backpressure to CME (blocking output)."
            },
            "job_meta_buffer": {
              "purpose": "In-memory buffer for Recon-meta DTOs (from Recon-meta Management).",
              "persistence": "NOT persistent.",
              "capacity_batch_metadata_dtos": 100,
              "overflow_behavior": "Oldest entries overwritten (LRU)."
            }
          },
          "kafka_producers_internal": {
            "matching_output_producer": {
              "topic": "Matching_Output_Topic",
              "source_buffer": "RECON BUCKET",
              "producer_configuration": "acks=all, retries=5, batch.size=16384 bytes, linger.ms=100ms. Utilize central fault-tolerance library for adaptive pacing."
            },
            "escalation_output_producer": {
              "topic": "Escalation_Topic",
              "source_buffer": "URE BUCKET",
              "producer_configuration": "acks=all, retries=5, batch.size=16384 bytes, linger.ms=100ms. Adaptive pacing highly recommended."
            },
            "recon_meta_output_producer": {
              "topic": "Recon_Metadata_Topic",
              "source_buffer": "JOB_META Buffer",
              "producer_configuration": "acks=all, retries=5, batch.size=16384 bytes, linger.ms=100ms. Adaptive pacing recommended."
            }
          },
          "serialization_formats": {
            "matched_quants": "Avro with Schema Registry integration.",
            "ure_quants": "Avro with Schema Registry integration.",
            "recon_meta_dto": "Avro with Schema Registry integration."
          }
        },
        "error_handling_dlq": {
          "role": "Cross-cutting concern ensuring resilience and data integrity within Maas. Captures and isolates Quants failing internal Maas processing.",
          "error_categories": [
            "MATCH_RULE_EXECUTION_FAILURE",
            "INVALID_STATE_FOR_MATCH",
            "UNEXPECTED_DATA_PATTERN",
            "EXTERNAL_LOOKUP_FAILURE_TRANSIENT",
            "EXTERNAL_LOOKUP_FAILURE_PERMANENT",
            "BUFFER_OVERFLOW",
            "KAFKA_PRODUCER_FAILURE",
            "DESERIALIZATION_ERROR"
          ],
          "dlq_strategy": "Dedicated Kafka DLQ topic (Maas_DLQ_Topic) with 7-day retention. Manual re-processing via external tool for failed messages.",
          "error_tagging": "Failed Quants (if routed to DLQ) are enriched with context (error code, message, timestamp, problematic fields, source transaction ID).",
          "logging_strategy": "Detailed error logging via logging-monitoring central library, including original message snippets for debugging."
        },
        "performance_scaling_manager": {
          "role": "Cross-cutting concern ensuring Maas meets its SLA contributions and operates efficiently.",
          "metrics_collection": {
            "description": "Emits detailed metrics to Monitoring as a Service via logging-monitoring central library.",
            "metrics": [
              {
                "name": "total Quants consumed",
                "type": "counter"
              },
              {
                "name": "total Quants produced",
                "type": "counter"
              },
              {
                "name": "matchedExactCount",
                "type": "counter_per_second_per_batch"
              },
              {
                "name": "fuzzyMatchedCount",
                "type": "counter_per_second_per_batch"
              },
              {
                "name": "ureCount",
                "type": "counter_per_second_per_batch"
              },
              {
                "name": "average_latency_per_match",
                "type": "gauge",
                "unit": "ms"
              },
              {
                "name": "P99_latency_per_match",
                "type": "gauge",
                "unit": "ms"
              },
              {
                "name": "internal_buffer_depths",
                "type": "gauge"
              },
              {
                "name": "CPU_Memory_Network_Disk_IO_utilization",
                "type": "gauge_aggregated"
              },
              {
                "name": "Kafka_consumer_lag",
                "type": "gauge_per_partition",
                "unit": "seconds"
              },
              {
                "name": "Kafka_producer_rates",
                "type": "gauge_per_topic",
                "unit": "records_per_second"
              },
              {
                "name": "cache_hit_ratio_lookups",
                "type": "gauge"
              },
              {
                "name": "cache_miss_ratio_lookups",
                "type": "gauge"
              }
            ]
          },
          "alerting": {
            "alert_rules": [
              {
                "name": "Critical_Kafka_Consumer_Lag",
                "severity": "CRITICAL",
                "condition": "Kafka consumer lag > 60 seconds",
                "notification_channel": "MonaaS, Central_Logging"
              },
              {
                "name": "Critical_Maas_Latency_Spike",
                "severity": "CRITICAL",
                "condition": "P99 Maas latency > 500ms",
                "notification_channel": "MonaaS, Central_Logging"
              },
              {
                "name": "Critical_London_Bridge_URE_Count",
                "severity": "CRITICAL",
                "condition": "URE count > 100 for a batch",
                "notification_channel": "MonaaS, Central_Logging"
              },
              {
                "name": "Warning_Error_Rate_Exceeded",
                "severity": "WARNING",
                "condition": "Error rate > 0.1%",
                "notification_channel": "MonaaS, Central_Logging"
              },
              {
                "name": "Error_Buffer_Full",
                "severity": "ERROR",
                "condition": "Internal buffer is full",
                "notification_channel": "MonaaS, Central_Logging"
              }
            ]
          },
          "internal_scaling": {
            "description": "Dynamically adjusts CME worker pool size based on internal load (e.g., consumer buffer depth, CPU utilization).",
            "logic_algorithm": "Dynamic adjustment of CME worker pool size (N) based on Kafka consumer buffer depth (if >75% capacity, N++ up to max; if <25% capacity, N-- down to min). Max N = 2x CPU cores, Min N = 4 threads."
          },
          "external_scaling_hpa": {
            "description": "How Maas instances scale horizontally in Kubernetes/cloud environment.",
            "criteria": [
              {
                "name": "Kafka_consumer_lag",
                "source": "KEDA",
                "target_value": 30,
                "unit": "seconds"
              },
              {
                "name": "average_CPU_utilization",
                "value": 60,
                "unit": "percent"
              }
            ],
            "replicas_min": 2,
            "replicas_max": 8
          },
          "distributed_tracing": "Use of distributed tracing (e.g., OpenTelemetry via security central library) to trace a single transaction's journey through Maas stages."
        },
        "cross_cutting_concerns": {
          "central_library_dependencies": [
            "dto",
            "validation",
            "config",
            "pci",
            "security",
            "resilience",
            "error",
            "monitoring"
          ],
          "fault_tolerance_application": {
            "adaptive_pacing_kafka_producer": "Utilize central fault-tolerance library"
          },
          "testing_strategy": {
            "unit_tests": "High coverage for matching algorithms and rule logic.",
            "integration_tests": "Kafka consumer/producer interactions, rule loading, internal component interactions.",
            "performance_tests": "Simulated transaction matching up to 10,000 Quants/day to validate SLA slice and latency targets.",
            "contract_tests": "Schema compatibility with Matching_Input_Topic and all output topics (Matching_Output_Topic, Escalation_Topic, Recon_Metadata_Topic)."
          }
        }
      },
    "reporter": {
      "service_id": "REPAAS-POC-V1.0-20250704",
      "scope": "PoC",
      "cir": 95,
      "adi": 100,
      "service_identity": {
        "name": "Reporting",
        "aliases": "RepaaS",
        "semantic_role": "analytical_reporting_from_kafka_persistence",
        "classification": "support_service",
        "criticality_level": "tier_2_post_reconciliation"
      },
      "processing_semantic": {
        "reporting_scope_and_granularity": {
          "job_level_reconciliation_summary": {
            "description": "Single report for an entire 30-minute job, printing all batches chronologically within that job.",
            "content_detail": "Batch ID, total input quants, matched count, URE count per batch, arranged chronologically within a job report.",
            "granularity": "Job-level aggregation of batch data"
          },
          "weekly_ure_trend_report": {
            "description": "Counts of UREs by reason code over time.",
            "granularity": "Daily/Weekly Aggregation"
          }
        },
        "data_sources_and_model": {
          "kafka_input_topics": [
            "Recon_Metadata_Topic",
            "Escalation_Topic",
            "Matching_Output_Topic"
          ],
          "persistence_layer": {
            "database_type": "Kafka_Streams_State_Store",
            "role": "Internal, localized, fault-tolerant persistence for read models.",
            "technology": "Apache Kafka Streams (KTable/KStream aggregations)",
            "note": "Strictly no external database connection (e.g., MongoDB)."
          },
          "internal_data_model_conceptual": "Kafka Streams KTables for materialized views of job summaries, batch details, and URE trends."
        },
        "query_patterns_and_performance": {
          "expected_query_patterns": "Querying Kafka Streams local state stores by job ID, date range, URE reason codes.",
          "query_response_times": {
            "job_level_report_generation_p95_seconds": 5,
            "weekly_trend_reports_p95_seconds": 10
          }
        },
        "data_latency_and_freshness": {
          "report_availability_latency_minutes": 15,
          "max_data_staleness_minutes": 15,
          "consistency_model": "Eventual Consistency"
        },
        "user_concurrency_and_report_generation_volume": {
          "concurrent_users_viewing_reports": 5,
          "report_generation_volume": {
            "daily_job_reports_generated": 1,
            "weekly_trend_reports": 5,
            "api_exports_per_day": 10
          },
          "poc_data_volume_quants_max_per_job": 10000
        },
        "report_distribution_and_delivery": {
          "delivery_mechanism": [
            "Web UI Access",
            "Report Export API"
          ],
          "web_ui_endpoint": "/reports",
          "export_api_endpoints": [
            {
              "type": "Job_Report_Export",
              "uri": "/api/reports/job/{jobId}/export",
              "http_method": "GET",
              "export_formats": [
                "CSV",
                "JSON"
              ]
            },
            {
              "type": "URE_Trend_Report_Export",
              "uri": "/api/reports/ure/trend/export",
              "http_method": "GET",
              "export_formats": [
                "CSV",
                "JSON"
              ]
            }
          ],
          "security_model": "Basic authentication for POC scope (API and UI)."
        },
        "scalability_and_archival": {
          "expected_growth_period_months": 12,
          "projected_growth_target": {
            "data_volume_increase_x": 2,
            "concurrent_users_increase_x": 2,
            "report_generation_increase_x": 2
          },
          "future_solution_recommendation": "Scaling Kafka Streams instances, dedicated reporting microservice cluster, integration with external BI tools/data warehouses (potentially with more robust external persistence).",
          "archival_strategy": "Offload historical Kafka topic data older than 1 year to cold storage (e.g., S3); Kafka Streams state stores would rebuild from compacted topics upon restart/rebalance."
        }
      },
      "resource_constraints_for_poc": {
        "max_ram_mb": 1024,
        "max_cpu_usage_percent_of_single_core": 75
      },
      "sub_components_semantic": {
        "kafka_consumer_group": {
          "order": 1,
          "responsibility": "Parallel consumption of Kafka input topics (Recon_Metadata, Escalation, Matching_Output)"
        },
        "data_buffer": {
          "order": 2,
          "responsibility": "In-memory buffer for incoming Kafka messages before stream processing"
        },
        "report_preparation_arena": {
          "order": 3,
          "responsibility": "Stateful Kafka Streams application for aggregating/materializing data for job-level and trend reports (KTables)"
        },
        "report_generator": {
          "order": 4,
          "responsibility": "Transforms materialized report data from Kafka Streams state stores into final report format (CSV/JSON)"
        },
        "export_rest_api": {
          "order": 5,
          "responsibility": "Exposes HTTP endpoints for report generation requests and downloading generated reports"
        }
      },
      "cross_cutting_concerns": {
        "central_library_dependencies": [
          "dto",
          "config",
          "security",
          "error",
          "monitoring"
        ],
        "fault_tolerance_application": {
          "kafka_streams_resilience": "Leverages Kafka Streams' fault tolerance for state store recovery and processing guarantees."
        },
        "testing_strategy": {
          "unit_tests": "High coverage for Kafka Streams topologies, report generation logic, and API endpoints.",
          "integration_tests": "Kafka Streams application end-to-end with simulated Kafka topics, API endpoint testing.",
          "performance_tests": "Simulated report generation and API export load to validate query response times and resource constraints.",
          "contract_tests": "Schema compatibility with input Kafka topics and output report formats (CSV/JSON)."
        }
      }
    },
    "escalator": {
      "service_id": "ESCAL-SVC-001-PAIRCODE-V1.0-20250705",
      "scope": "PoC",
      "cir": 95,
      "adi": 100,
      "service_identity": {
        "name": "Escalation",
        "aliases": "ExaaS",
        "semantic_role": "human_workflow_ure_resolution",
        "classification": "business_support_service",
        "criticality_level": "tier_2_post_reconciliation"
      },
      "processing_semantic": {
        "objective": {
          "description": "Develop a functional Proof of Concept (POC) for Escalation-as-a-Service (ExaaS).",
          "quantified_goal": "Deliver a working POC of ExaaS within 90 minutes of dedicated pair-coding time.",
          "metrics": [
            "Code Completeness: Core ExaaS components functional.",
            "Functional Flow: Demonstration of URE ingestion, persistence, status update, and API interaction.",
            "Alert Trigger: Ability to demonstrate 'London Bridge' alert on exceeding 100 UREs for a job."
          ]
        },
        "in_scope_functionality": [
          {
            "function": "Consume UREs from Kafka",
            "source": "Escalation_Topic",
            "mechanism": "Kafka Consumer Group (KCG)",
            "constraints": {
              "max_consumption_rate_ures_per_second_peak": 5,
              "max_consumer_lag_tolerance_seconds": 10
            }
          },
          {
            "function": "Manage internal buffers for data flow",
            "mechanism": "java.util.concurrent.LinkedBlockingQueue",
            "detail": "From KCG to MongoDB persistence system.",
            "constraints": {
              "buffer_capacity_ures": 5000,
              "batch_write_size_ures_per_batch": 100,
              "overflow_behavior": "Route to Kafka DLQ topic",
              "dlq_kafka_topic_name": "ure-dlq-topic"
            }
          },
          {
            "function": "Read/write UREs to MongoDB",
            "role": "Source of truth ledger for unmatched/weird items.",
            "constraints": {
              "max_rw_qps_peak": 10,
              "target_persistence_latency_p99_ms": 100
            }
          },
          {
            "function": "Support 'Inspection Arena' concept",
            "detail": "UREs presented for manual inspection by `bankops` (no UI from ExaaS)."
          },
          {
            "function": "Implement 'Status Tracker'",
            "detail": "Observe UREs entering Inspection Arena and update their status in MongoDB Ledger."
          },
          {
            "function": "Implement 'Lean but Powerful Curing Algorithm'",
            "detail": "Human-dependent workflow to try and correct URE issues inside Inspection Arena (not automated curing).",
            "constraints": {
              "workflow_states": [
                "PENDING_REVIEW",
                "IN_PROGRESS",
                "RESOLVED",
                "REJECTED"
              ]
            }
          },
          {
            "function": "Provide 'Escalation Curing API'",
            "type": "REST API",
            "consumer": "`bankops`",
            "detail": "To interact with UREs in Inspection Area (cure, update status).",
            "constraints": {
              "api_endpoints": [
                {
                  "uri": "/api/ures/{id}/cure",
                  "method": "POST"
                },
                {
                  "uri": "/api/ures/{id}/status",
                  "method": "PUT"
                }
              ],
              "request_response_schemas": [
                {
                  "name": "CureRequest",
                  "type": "JSON_SCHEMA_REFERENCE"
                },
                {
                  "name": "StatusUpdateRequest",
                  "type": "JSON_SCHEMA_REFERENCE"
                },
                {
                  "name": "UreResponse",
                  "type": "JSON_SCHEMA_REFERENCE"
                }
              ],
              "custom_error_codes": [
                "URE_NOT_FOUND",
                "INVALID_STATUS_TRANSITION"
              ],
              "target_api_latency_p99_ms": 200
            }
          },
          {
            "function": "Trigger 'SYSTEM ALERT: Code London Bridge Is Falling Down'",
            "condition": "UREs exceed 100 (1% of 10K total load in a 30min job).",
            "constraints": {
              "alert_mechanism": "Log to system stdout/file, publish to monitoring Kafka topic (if integrated)",
              "alert_notification_channel": "System logs, dedicated monitoring dashboard"
            }
          }
        ],
        "out_of_scope_functionality": [
          "Automated URE curing beyond simple rules or workflow management.",
          "Full historical reporting/auditing within ExaaS beyond the MongoDB ledger's current state (delegated to external systems).",
          "Deployment to Docker/Cloud environments (POC is native Windows only).",
          "High Availability (HA) or automated failover for the single ExaaS instance (POC constraint).",
          "Graphical User Interface (GUI) for Inspection Arena or Curing API (API only)."
        ]
      },
      "technology_alignment": {
        "programming_language": "Java 21",
        "framework": "Spring Boot",
        "build_tool": "Maven",
        "message_broker": "Apache Kafka",
        "stream_processing": "Apache Kafka Streams",
        "persistence": "MongoDB (for URE Ledger)",
        "api_framework": "Spring Web",
        "common_libraries": [
          "common_dto",
          "validation_utils",
          "config_utils",
          "pci_dss",
          "security",
          "fault_tolerance",
          "error_handling",
          "logging_monitoring"
        ]
      },
      "risk_assessment_details": [
        {
          "id": "ESCAL-R-001",
          "type": "Performance/Resource",
          "status": "Mitigated by Design",
          "description": "URE Volume: System design optimized for high volume. POC load is 50K txns total; 'London Bridge' alert covers high URE count (100).",
          "mitigation": "Internal buffers, batch writing, Kafka Consumer Group for parallel consumption, robust MongoDB configuration for scale.",
          "quantified_context": {
            "max_ure_throughput_poc_ures_per_second_peak": 5,
            "cpu_memory_target_peak_load": {
              "max_ram_mb": 512,
              "max_cpu_usage_percent_single_core": 50
            }
          }
        },
        {
          "id": "ESCAL-R-002",
          "type": "SinglePointOfFailure",
          "status": "Accepted for POC",
          "description": "The POC will run as a single instance, making it a SPOF.",
          "mitigation_for_prod": "Implement multi-instance deployment with Kafka Consumer Group for HA and load balancing."
        },
        {
          "id": "ESCAL-R-003",
          "type": "Consistency",
          "status": "Mitigated by Design",
          "description": "Status Consistency: Achieved using `read-your-writes` consistency via MongoDB session transactions or `majority` write concern with `primary` read preference on replica set.",
          "mitigation": "Appropriate MongoDB write/read concerns and transaction implementation."
        },
        {
          "id": "ESCAL-R-004",
          "type": "Audit/Compliance",
          "status": "Mitigated by Design",
          "description": "MongoDB Auditability/Transactions: Achieved using `MongoDB Multi-Document Transactions` for atomicity, ensuring `immutable fields` (`createdAt`, `createdBy`), and capturing `Change Streams` for an external audit log.",
          "mitigation": "Robust schema design, transaction usage, and external audit log integration."
        },
        {
          "id": "ESCAL-R-005",
          "type": "BufferManagement",
          "status": "Mitigated by Design",
          "description": "Buffer Specifics: Managed by `java.util.concurrent.LinkedBlockingQueue` for in-memory, with configured capacity, `batching writes` to MongoDB, and routing overflow to a Kafka `DLQ` topic.",
          "mitigation": "Explicit buffer design and error handling (DLQ)."
        },
        {
          "id": "ESCAL-R-006",
          "type": "ImplementationComplexity",
          "status": "Mitigated by Design",
          "description": "Curing Algorithm Workflow: Defined as a human-dependent workflow with clear steps and an alert threshold, reducing coding ambiguity.",
          "mitigation": "Focus on implementing key workflow states and API interactions; leverage Gemini Pro for rapid code generation for known patterns."
        },
        {
          "id": "ESCAL-R-007",
          "type": "APIContractDefinition",
          "status": "Mitigated by Design",
          "description": "API Contracts: Clear endpoints, request/response schemas (JSON), and explicit error codes (HTTP + custom) for `Escalation Curing API` defined.",
          "mitigation": "Automated code generation for API interfaces based on defined contracts."
        },
        {
          "id": "ESCAL-R-008",
          "type": "EnvironmentSpecific",
          "status": "Mitigated by Override",
          "description": "Windows Native Environment: Potential setup/compatibility issues.",
          "mitigation": "Resolved by `override_cq2025` grant; environment will be prepared/managed to ensure readiness."
        },
        {
          "id": "ESCAL-R-009",
          "type": "DependencyManagement",
          "status": "Mitigated by Override",
          "description": "Common Library Access/Configuration: Potential time loss on dependency issues.",
          "mitigation": "Resolved by `override_cq2025` grant; common libraries will be confirmed/configured."
        }
      ],
      "cross_cutting_concerns": {
        "central_library_dependencies": [
          "common_dto",
          "validation_utils",
          "config_utils",
          "pci_dss",
          "security",
          "fault_tolerance",
          "error_handling",
          "logging_monitoring"
        ],
        "fault_tolerance_application": {
          "retries": "Configured for external calls (e.g., MongoDB, Kafka Producer)",
          "circuit_breakers": "Applied to external dependencies (e.g., MongoDB, Kafka Producer)",
          "timeouts": "Configured for all external I/O operations"
        },
        "testing_strategy": {
          "unit_tests": "High coverage for API logic, MongoDB interactions, and URE status transitions.",
          "integration_tests": "Kafka consumer/producer interactions, MongoDB persistence, API endpoint testing.",
          "performance_tests": "Simulated API calls and URE ingestion load to validate QPS and latency targets.",
          "contract_tests": "Schema compatibility with Kafka input topics and API request/response formats."
        }
      }
    },
    "monitor": {
      "service_id": "MON-SVC-001-FINAL",
      "scope": "PoC",
      "cir": 98,
      "adi": 100,
      "service_identity": {
        "name": "Monitoring",
        "aliases": "MonaaS",
        "semantic_role": "realtime_metrics_aggregation_alerting",
        "classification": "support_service",
        "criticality_level": "tier_2_for_visibility_tier_1_for_reporting_core_sla"
      },
      "processing_semantic": {
        "input_model": {
          "mechanism": "HTTP_Polling",
          "source_microservices": [
            "NaaS",
            "RecBatchOrch",
            "Maas",
            "Reporting",
            "Escalation"
          ],
          "endpoints_polled": [
            {
              "type": "standard_actuator_health",
              "uri": "/actuator/health"
            },
            {
              "type": "custom_actuator_job_status",
              "uri": "/actuator/job-status"
            }
          ]
        },
        "metrics_collected": {
          "standard_actuator_metrics": [
            {
              "name": "jvm.memory.used",
              "tags": "service_name"
            },
            {
              "name": "jvm.memory.max",
              "tags": "service_name"
            },
            {
              "name": "jvm.threads.live",
              "tags": "service_name"
            },
            {
              "name": "system.cpu.usage",
              "tags": "service_name"
            },
            {
              "name": "process.uptime",
              "tags": "service_name"
            },
            {
              "name": "http.server.requests.count",
              "tags": "service_name,uri,method,status"
            },
            {
              "name": "http.server.requests.duration.p95",
              "tags": "service_name,uri,method"
            }
          ],
          "custom_job_specific_metrics": [
            {
              "name": "reconciliation.job.status",
              "tags": "service_name,job_id",
              "type": "Enum(STARTED,IN_PROGRESS,COMPLETED,FAILED)"
            },
            {
              "name": "reconciliation.job.start.time",
              "tags": "service_name,job_id",
              "type": "Timestamp"
            },
            {
              "name": "reconciliation.job.end.time",
              "tags": "service_name,job_id",
              "type": "Timestamp"
            },
            {
              "name": "reconciliation.transactions.processed.total",
              "tags": "service_name,job_id",
              "type": "Counter"
            }
          ],
          "overall_job_metrics_calculated_by_monaas": [
            {
              "name": "overall.reconciliation.job.elapsed.time"
            },
            {
              "name": "overall.reconciliation.job.status"
            }
          ]
        },
        "collection_frequency": {
          "polling_interval_seconds": 10
        },
        "data_retention": {
          "current_state_store": {
            "type": "in_memory",
            "retention_period_unit": "hour",
            "retention_period_value": 1,
            "scope": "latest_granular_per_service"
          },
          "job_run_history_log": {
            "type": "file_log",
            "retention_period_unit": "hours",
            "retention_period_value": 24,
            "scope": "overall_job_summary"
          }
        },
        "alerting_logic": {
          "alert_rules": [
            {
              "name": "Critical_Service_Down",
              "severity": "CRITICAL",
              "condition": "ServiceHealthStatus is DOWN for 2 consecutive polls (20 seconds)",
              "notification_channel": "stdout, monaas-alerts.log"
            },
            {
              "name": "Critical_Job_Failure",
              "severity": "CRITICAL",
              "condition": "overall.reconciliation.job.status is FAILED",
              "notification_channel": "stdout, monaas-alerts.log"
            },
            {
              "name": "Critical_SLA_Breach",
              "severity": "CRITICAL",
              "condition": "overall.reconciliation.job.elapsed.time > 30 minutes at job completion",
              "notification_channel": "stdout, monaas-alerts.log"
            },
            {
              "name": "Warning_High_CPU",
              "severity": "WARNING",
              "condition": "system.cpu.usage > 85% for 3 consecutive polls (30 seconds)",
              "notification_channel": "stdout, monaas-alerts.log"
            },
            {
              "name": "Warning_High_Error_Rate",
              "severity": "WARNING",
              "condition": "http.server.requests.count (for errors) indicates error rate > 1% of total requests over last 1 minute",
              "notification_channel": "stdout, monaas-alerts.log"
            }
          ]
        },
        "data_volume_projection": {
          "unique_time_series_estimate": 120,
          "data_points_per_second_ingestion": 12,
          "current_state_store_memory_estimate_mb": 50
        },
        "latency_targets": {
          "metric_to_dashboard_display_latency_seconds": 15,
          "alert_condition_to_logged_latency_seconds": 5
        },
        "future_scalability": {
          "current_capacity_microservices": 5,
          "expected_growth_period_months": 12,
          "projected_growth_target": "10_microservices (2x), 2x_metric_volume",
          "future_solution_recommendation": "Dedicated Prometheus/Grafana stack with persistent time-series storage"
        }
      },
      "sub_components_semantic": {
        "service_polling_agent": {
          "responsibility": "Initiates_HTTP_polling_requests"
        },
        "raw_status_ingester": {
          "responsibility": "Parses_and_validates_raw_HTTP_responses"
        },
        "overall_job_state_processor": {
          "responsibility": "Aggregates_and_calculates_overall_job_status"
        },
        "current_state_store": {
          "responsibility": "In_memory_cache_for_latest_statuses"
        },
        "dashboard_renderer": {
          "responsibility": "Generates_simple_web_UI"
        },
        "sla_health_alerting": {
          "responsibility": "Monitors_state_triggers_log_alerts"
        }
      },
      "cross_cutting_concerns": {
        "central_library_dependencies": [
          "logging_monitoring",
          "error_handling"
        ],
        "testing_strategy": {
          "unit_tests": "High coverage for polling logic, metric aggregation, and alert condition evaluation.",
          "integration_tests": "Simulated HTTP polling against mock service endpoints, alert logging verification.",
          "performance_tests": "Simulated metric ingestion volume to validate latency targets and resource utilization.",
          "contract_tests": "Verification of expected metric formats from polled endpoints."
        }
      }
    }
  }
}
